---
title: "EpiSewer Review"
format: html
editor: visual
---

## Libraries

```{r}
library(MARSS)
library(tidyverse)
library(KFAS)
library(ggplot2)
library(astsa)
library(dplyr)
library(data.table)
library(tseries)
library(knitr)
library(latexpdf)
library(kableExtra)
library(forecast)
library(qcc)
library(ggnewscale)
library(remotes)
library(EpiSewer)
```

```{r}

# synthetic_data <- synthetic_data %>%
#   pivot_longer(
#     cols = -date,  # Selecciona todas las columnas excepto la de fechas
#     names_to = "WWTP",  # El nombre de la columna que contendrá los nombres de WWTP
#     values_to = "log10cpl"  # El nombre de la columna que contendrá las cargas virales
#   )
# 
# synthetic_data <- synthetic_data %>%
#   filter(WWTP %in% c("69TH STREET"))
# 
# 
# # Filter the flow data to the desired date range
# flow_data <- flow_data %>%
#   filter(date >= "2020-10-19" & date <= "2023-05-29")
# flow_data <- flow_data %>%
#   filter(WWTP %in% c("69TH STREET"))
# 
# # Merge the flow data with the synthetic data based on the date. Any missing flow data will be interpolated. Also, add some noise to the flow data.
# 
# # Convert the date column in flow_data to Date type
# flow_data <- flow_data %>%
#   mutate(date = as.Date(date))
# 
# # Proceed with the left_join and add noise
# synthetic_data <- synthetic_data %>%
#   left_join(flow_data, by = c("date", "WWTP")) %>%
#   mutate(flow = flow + rnorm(n = nrow(synthetic_data), mean = 0, sd = 0.05 * mean(flow, na.rm = TRUE))) 

# Remove population and outliers columns
#synthetic_data <- synthetic_data %>%
#  select(-pop, -outlier)

# Save the synthetic data
#save(synthetic_data, file = "Data/synthetic_data")

# Ver el data frame transformado
#head(synthetic_data)

# Filter out "SIMS BAYOU" from the observed data
#all_ts_observed <- all_ts_observed %>% 
#  dplyr::filter(WWTP != "SIMS BAYOU") 

## DEFINE PARAMETERS:
burnin <- 15  # Interesting Variance behavior 
date_burnin <- synthetic_data %>% 
  dplyr::filter(WWTP == '69TH STREET') %>% 
  dplyr::select(date) %>% 
  nth(burnin) %>%
  pull(date)

# Filter the time series data post-burnin and arrange by date
ts_data <- synthetic_data %>%
  dplyr::filter(date > date_burnin) %>%
  arrange(date)

# Focus on specific WWTPs
WWTP_focus <- c("69TH STREET")

#ts_data <- ts_data %>%
#  dplyr::filter(WWTP %in% WWTP_focus)

# Add constant flow per plant (250 million gallons of wastewater daily for each WWTP)
#constant_flow <- 250e6
# Change to L/day
#constant_flow <- constant_flow * 3785.41

# Add a new column for the flow data to ts_data L/day
#error_sd <- 0.05  # 5% standard deviation for normal distribution
#error_range <- 0.1  # 10% variation for uniform distribution
#ts_data <- ts_data %>%
#  mutate(flow = constant_flow )#+ rnorm(n = nrow(ts_data), mean = 0, sd = error_sd * constant_flow))

# Change the concentration to from log10 to linear 
#ts_data$log10cpl <- 10^ts_data$log10cpl
# Change from copies per liter to copies per mililiter
#ts_data$log10cpl <- ts_data$log10cpl * 1000
# Change names to concentration
ts_data <- ts_data %>%
  mutate(concentration = log10cpl) %>%
  dplyr::select(-log10cpl)
# Change the water flow by transforming to log 10
#ts_data$flow <- log10(ts_data$flow)

# Process the dates for the time series
#dates <- ts_data %>%
#  dplyr::select(date, WWTP, concentration) %>%
#  pivot_wider(names_from = WWTP, values_from = concentration) %>%
 # dplyr::select(date) %>%
 # distinct() %>%
#  pull() %>%
#  as.Date() 

# Create the time series matrix
#ts_matrix <- ts_data %>%
#  dplyr::select(date, WWTP, concentration) %>%
#  pivot_wider(names_from = WWTP, values_from = concentration) %>%
#  dplyr::select(-date) %>%
#  as.matrix()

# Extract WWTP names
wwtp_names <- colnames(ts_data)

# Now the ts_data dataframe includes the constant flow for each WWTP
print(ts_data)
```

## Description of the data

The data consists of synthetic time series data based on the observations of SARS-CoV-2 concentrations in wastewater samples collected from various wastewater treatment plants (WWTPs) in Houston, Texas, USA. The data includes the date of collection, the WWTP from which the sample was collected, the log10-transformed concentration of SARS-CoV-2 RNA copies per liter (log10cpl), and other relevant information.

The goal is to analyze the data using the EpiSewer package to estimate the dynamics of the SARS-CoV-2 outbreak in Houston based on the wastewater surveillance data.

The cases data is not available, so we will initialize an empty column for cases in the data.

## 1. Data Processing

The total viral load, $\pi_t$, is calculated as:

$$ \pi_t = C_t \times \text{flow}_t  $$

Where:

-   $\pi_t$: Total viral load (gc/day) on day $t$.

-   $C_t$: Viral concentration (gc/L).

-   $\text{flow}_t$: Flow rate (L/day).

```{r}
load("Data/synthetic_data")

# Filter the time series data post-burnin and arrange by date
# DEFINE PARAMETERS:
burnin <- 15  # Interesting Variance behavior 
date_burnin <- synthetic_data %>% 
  dplyr::filter(WWTP == '69TH STREET') %>% 
  dplyr::select(date) %>% 
  nth(burnin) %>%
  pull(date)

# Filter the time series data post-burnin and arrange by date
ts_data <- synthetic_data %>%
  dplyr::filter(date > date_burnin) %>%
  arrange(date)

# Change flow to mL/day
ts_data$flow <- ts_data$flow 
# Remove the log10 transformation
ts_data$log10cpl <- 10^ts_data$log10cpl

# Focus on specific WWTPs
WWTP_focus <- c("69TH STREET")

# Change names to concentration
ts_data <- ts_data %>%
  mutate(concentration = log10cpl) %>%
  dplyr::select(-log10cpl)

wwtp_data <- ts_data %>%
    dplyr::filter(WWTP == WWTP_focus)

# Convert filtered data to data.table
ww_data <- data.table::setDT(wwtp_data)
  
# Select relevant columns and rename
ww_data <- ww_data[, .(date, concentration, flow)]

# Calculate total viral load (πt) based on concentration and flow
ww_data[, total_viral_load := concentration * flow]
```

## 2. Initialize cases Column with NA Values

-   Adds a cases column and assigns NA values to 10% of rows to simulate missing data. This prepares the data to handle gaps in case data, modeling realistic missing data scenarios.

Comment: Although the package indicates that the cases column is optional, it is important to consider it for analyzing the virus spread.

```{r}
# Initialize 'cases' with NA values (if relevant)
ww_data[sample(1:nrow(ww_data), 0.1 * nrow(ww_data)), cases := NA]
```

## 3. Interpolate Missing Flow Data Using locf

-   Interpolates missing flow data using the last observation carried forward (locf) method, which fills missing values with the last observed value. This ensures that the flow data is continuous and complete, which is essential for accurate modeling and forecasting.

```{r}
# Interpolate missing flow data using 'locf'
ww_data <- ww_data[
    data.table::CJ(date = seq.Date(min(date), max(date), by = "day"), unique = TRUE),
    on = .(date)
  ]
data.table::setnafill(ww_data, type = "locf", cols = "flow")
```

```{r}
# Remove duplicates based on date
ww_data <- ww_data[!duplicated(date), ]
```

## 5. Create EpiSewer Input List

-   Creates an input list for EpiSewer containing the wastewater measurements, flow data, and cases data. This prepares the data for modeling the dynamics of the disease outbreak in the city based on the wastewater surveillance data.

-   Organizes measurements, flows, and cases into a list (ww_sewer) required by the model. Organizing data this way aligns with the expected structure for EpiSewer input.

-Comment: Although the cases data is optional, the EpiSewer package still requires it to be included in the input list. If we have no data on cases, we can initialize the column with NA values as done in the previous step.

```{r}
ww_sewer <- list(
    measurements = ww_data[, .(date, concentration)],
    flows = ww_data[, .(date, flow)],
    cases = ww_data[, .(date, cases)]
  )
```

## 6. Define the Measurement Model

Specifies the measurement model for concentrations and includes observed noise. We assume there is no limit of detection (LOD_none()), meaning all measurements are detectable.

```{r}
  ww_measurements <- model_measurements(
    concentrations = concentrations_observe(measurements = ww_sewer$measurements),
    noise = noise_estimate(),
    LOD = LOD_none()
  )
```

## 7. Define the Sewage Model

-   Specifies the sewage model, including the observed flow data and the assumed residence distribution. The residence distribution represents the time it takes for wastewater to travel from the source to the sampling point. Virus remains in the wastewater system for one day before being eliminated.

```{r}
  ww_sewage <- model_sewage(
    flows = flows_observe(flows = ww_sewer$flows),
    residence_dist = residence_dist_assume(residence_dist = c(1))
  )
```

## 8. Sampling Model

-   Specifies the sampling model, assuming no sample effects. The sampling process does not affect the observed data.

```{r}
  ww_sampling <- model_sampling(
    sample_effects = sample_effects_none()
  )
```

## 9. Shedding Model

Expected Symptom Onsets ($\lambda_t$):

$\lambda_t$ represents the expected number of individuals with symptom onset on day $t$.

$$ \lambda_t = \sum_{s=0}^{L} I_{t-s} \, \tau^{\text{inc}}_s .$$ Where:

-   $\tau^{\text{inc}}$: Incubation period distribution with maximum duration $L$.

-   $I_{t-s}$: Number of infections occurring $s$ days before.

The incubation distribution adjusts the delay between infection and symptom onset.

Total Load Shed in Catchment ( $\omega_t$ ):

$$ \omega_t = \sum_{s=0}^{S} \lambda_{t-s} \, \mu^{\text{load}} \, \tau^{\text{shed}}_s$$

Where:

-   $\mu^{\text{load}}$: Average viral load per individual.

-   $\tau^{\text{shed}}$: Shedding distribution with maximum duration $S$.

-   $S$: Maximum number of days after symptom onset.

```{r}
ww_shedding <- model_shedding(
    shedding_dist = shedding_dist_assume(
      get_discrete_gamma(gamma_shape = 0.929639, 
                         gamma_scale = 7.241397, 
                         maxX = 30),
      shedding_reference = "symptom_onset"),
    incubation_dist = incubation_dist_assume(get_discrete_gamma(gamma_shape = 8.5, 
                                                                gamma_scale = 0.4, 
                                                                maxX = 10)),
    load_per_case = load_per_case_calibrate(cases = NULL, min_cases = 25), 
    load_variation = load_variation_estimate()
  )
```

The number of infections at time $t$, denoted $I_t$, follows a Poisson distribution:

$$
I_t | \iota_t \sim \text{Poisson}(\iota_t) 
$$

In Stan, this may be approximated by a Normal distribution:

$$ I_t | \iota_t \sim N(\iota_t, \iota_t). $$

Estimating $R_t$:

The effective reproduction number, $R_t$, is estimated using a random walk model. The random walk model assumes that the transmission rate changes gradually over time, reflecting the underlying dynamics of the outbreak.

$R_t < 1$: Indicates that the outbreak is under control and will eventually subside.

$R_t = 1$: Indicates that the outbreak is stable, with the number of new cases remaining constant over time.

$R_t > 1$: Indicates that the outbreak is growing, with the number of new cases increasing.

$R_t$ is estimated using a renewal equation:

$$ \iota_t = R_t \sum_{s=1}^{G} \tau^{\text{gen}}_s I_{t-s} $$

Where:

-   $\iota_t$: Expected new infections at time $t$.

-   $\tau^{\text{gen}}_s$: Generation time distribution, representing the probability of transmission $s$ days after infection.

-   $I_{t-s}$: Number of infections $s$ days prior.

-   $G$: Maximum number of days considered for transmission.

$R_t$ is modeled as a random walk to allow for temporal variability: $$
        R_t \sim R_{t-1} + \epsilon .
        $$

```{r}
ww_infections <- model_infections(
  generation_dist = generation_dist_assume(
    get_discrete_gamma_shifted(gamma_mean = 3, 
                               gamma_sd = 2.4, 
                               maxX = 12)
    ),
  R = R_estimate_rw(),  # Use random walk instead of splines
  seeding = seeding_estimate_rw(),
  infection_noise = infection_noise_estimate()
)
```

## 11. Assumptions

The following are hard assumptions made in the model:

$\textbf{Generation Time Distribution}$ : Modeled with a shifted gamma distribution with a mean of 3 days, standard deviation of 2.4 days, and maximum of 12 days.

$$
G(t) \sim \text{Shifted Gamma}(\mu = 3, \sigma = 2.4, \text{ max} = 12)
$$

$\textbf{Shedding Distribution}$: Gamma distribution with shape = 0.929639, scale = 7.241397, and a maximum of 30 days from symptom onset.

$$
S(t) \sim \text{Gamma}(\text{shape} = 0.929639, \text{ scale} = 7.241397)
$$

$\textbf{Incubation Distribution}$: Gamma distribution with shape = 8.5, scale = 0.4, and a maximum incubation time of 10 days.

$$
I(t) \sim \text{Gamma}(\text{shape} = 8.5, \text{ scale} = 0.4)
$$

$\textbf{Limit of Detection (LOD)}$: Assumed as `LOD_none`, meaning all values are detectable.

$\textbf{Residence Time}$: Viral particles remain in the sewage system for 1 day.

$\textbf{No Clinical Case Data}$: Model operates based solely on wastewater data.

Comment: Notice that the model assumes that the minimum number of cases is 25. Therefore, although the cases column is initialized with NA values, the model requires a minimum number of cases to be present.

## 10. Forecast Model

-   Predicts up to 7 days into the future using posterior estimates of $R_t$ and other parameters.

```{r}
ww_forecast <- model_forecast(
    horizon = horizon_assume(horizon = 7)
  )
```

## 11. Fitting with MCMC

$\textbf{Method}$: Uses Stan-based MCMC for Bayesian inference.

$\textbf{Configuration}$: 250 warm-up iterations, 250 sampling iterations, with 2 chains running in parallel.

```{r}
  # Fit options
  ww_fit_opts <- set_fit_opts(
  model = model_stan_opts(package = "EpiSewer"),
  sampler = sampler_stan_mcmc(
    iter_warmup = 250,
    iter_sampling = 250,
    chains = 2,
    parallel_chains = 2,
    seed = 123
  )
)
```

## 12. Results Options and Episewer Run

Defines the 50% and 95% credibility intervals, with a total of 50 samples drawn for result evaluation.

Finally, the EpiSewer model is executed for the selected wastewater treatment plant with all previously defined components and settings.

```{r}
  ww_results_opts <- set_results_opts(
    fitted = TRUE,
    summary_intervals = c(0.5, 0.95),
    samples_ndraws = 50
  )

  # Run EpiSewer for the WWTP
  ww_result <- EpiSewer(
    measurements = ww_measurements,
    sampling = ww_sampling,
    sewage = ww_sewage,
    shedding = ww_shedding,
    infections = ww_infections,
    forecast = ww_forecast,
    fit_opts = ww_fit_opts,
    results_opts = ww_results_opts
  )
  
```

# 13. Results

This is the viral concentration concidering the flow of the wastewater. The normalization removes the noise due to the daily variation of flow. The remaining uncertainty is due to the measurement noise and other sources of variation. (From the website)

```{r}
#| results: asis
#| warning: false
#| echo: true
#| message: false
#| code-fold: true
#| outout: false
#| label: Concentration Plots

# Plot the results list
plot_concentration(ww_result, measurements = ww_sewer$measurements, flows = ww_sewer$flows, normalized = FALSE) +
      scale_x_date(date_labels = "%b %Y", date_breaks = "1 months") +  
      theme(axis.text.x = element_text(angle = 45, hjust = 1))

plot_concentration(ww_result, measurements = ww_sewer$measurements, flows = ww_sewer$flows, normalized = TRUE) +
      scale_x_date(date_labels = "%b %Y", date_breaks = "1 months") +  
      theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
#| results: asis
#| warning: false
#| echo: true
#| message: false
#| code-fold: true
#| outout: false
#| label: R_t Plots

# Generate Rt plot with forecast
plot_R(ww_result, forecast = TRUE) +
      scale_x_date(date_labels = "%b %Y", date_breaks = "1 months") +  # Fix overlapping dates
      theme(axis.text.x = element_text(angle = 45, hjust = 1)) +  # Rotate date labels
      labs(title = "Estimated Effective Reproduction Number (Rt) Over Time",  # Add title
           x = "Date", y = "Effective Reproduction Number (Rt)")  # Add axis labels

plot_R(ww_result, forecast = FALSE) +
      scale_x_date(date_labels = "%b %Y", date_breaks = "1 months") +  # Fix overlapping dates
      theme(axis.text.x = element_text(angle = 45, hjust = 1)) +  # Rotate date labels
      labs(title = "Estimated Effective Reproduction Number (Rt) Over Time",  # Add title
           x = "Date", y = "Effective Reproduction Number (Rt)")  # Add axis labels
```

When we apply a logarithmic $(\log_{10})$ transformation to the concentration data, it compresses the data range, smoothing fluctuations and making trends visually more stable. This transformation is especially useful when the data spans several orders of magnitude, as it reduces the impact of extremely high values and lowers the model's sensitivity to concentration changes. As a result, $R_t$ estimates tend to be nearly constant and less reactive to small variations.

In contrast, using untransformed concentration values introduces greater variability, allowing the model to capture more pronounced fluctuations and making $R_t$ reflect these changes more dynamically. This approach is more sensitive to natural variations in the data, capturing details in the transmission rate that may go unnoticed on a logarithmic scale. In summary, while the logarithmic transformation flattens trends and reduces the impact of high values, untransformed data allows for a more detailed and reactive estimation of $R_t$ in response to fluctuations.

```{r}
#| results: asis
#| warning: false
#| echo: true
#| message: false
#| code-fold: true
#| outout: false
#| label: Loads Plots

plot_load(ww_result) +
      scale_x_date(date_labels = "%b %Y", date_breaks = "1 months") +  # Fix overlapping dates
      theme(axis.text.x = element_text(angle = 45, hjust = 1))
plot_infections(ww_result)+
      scale_x_date(date_labels = "%b %Y", date_breaks = "1 months") +  # Fix overlapping dates
      theme(axis.text.x = element_text(angle = 45, hjust = 1))
names(ww_result)
names(ww_result$job)
head(ww_result$summary$R, 5)
ww_result$fitted$diagnostic_summary()
ww_result$checksums
```
